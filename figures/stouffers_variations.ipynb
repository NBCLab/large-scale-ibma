{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import seaborn as sns\n",
    "from nimare.transforms import p_to_z\n",
    "from nimare.results import MetaResult\n",
    "from nilearn.image import threshold_img\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from nilearn.plotting import find_xyz_cut_coords\n",
    "import os.path as op\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from neuromaps.datasets import fetch_atlas\n",
    "from nibabel.gifti import GiftiDataArray\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from neuromaps import transforms\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn import datasets\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "from nimare.transforms import d_to_g, p_to_z, t_to_d, z_to_t\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "from surfplot import Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = nilearn_cmaps[\"cold_hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_TO_HCP = {\n",
    "    \"working_memory_fmri_task_paradigm\": \"10_tfMRI_WM_2BK-0BK\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of vertices in total without the medial wall\n",
    "N_VERTICES = {\n",
    "    \"fsLR\": {\n",
    "        \"32k\": 59412,\n",
    "        \"164k\": 298261,\n",
    "    },\n",
    "    \"fsaverage\": {\n",
    "        \"3k\": 4661,\n",
    "        \"10k\": 18715,\n",
    "        \"41k\": 74947,\n",
    "        \"164k\": 299881,\n",
    "    },\n",
    "    \"civet\": {\n",
    "        \"41k\": 76910,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Number of vertices per hemisphere including the medial wall\n",
    "N_VERTICES_PH = {\n",
    "    \"fsLR\": {\n",
    "        \"32k\": 32492,\n",
    "        \"164k\": 163842,\n",
    "    },\n",
    "    \"fsaverage\": {\n",
    "        \"3k\": 2562,\n",
    "        \"10k\": 10242,\n",
    "        \"41k\": 40962,\n",
    "        \"164k\": 163842,\n",
    "    },\n",
    "    \"civet\": {\n",
    "        \"41k\": 40962,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rm_medial_wall(\n",
    "    data_lh,\n",
    "    data_rh,\n",
    "    space=\"fsLR\",\n",
    "    density=\"32k\",\n",
    "    join=True,\n",
    "    neuromaps_dir=None,\n",
    "):\n",
    "    \"\"\"Remove medial wall from data in fsLR space.\n",
    "\n",
    "    Data in 32k fs_LR space (e.g., Human Connectome Project data) often in\n",
    "    GIFTI format include the medial wall in their data arrays, which results\n",
    "    in a total of 64984 vertices across hemispheres. This function removes\n",
    "    the medial wall vertices to produce a data array with the full 59412 vertices,\n",
    "    which is used to perform functional decoding.\n",
    "\n",
    "    This function was adapted from :func:`surfplot.utils.add_fslr_medial_wall`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Surface vertices. Must have exactly 32492 vertices per hemisphere.\n",
    "    join : bool\n",
    "        Return left and right hemipsheres in the same arrays. Default: True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Vertices with medial wall excluded (59412 vertices total).\n",
    "\n",
    "    ValueError\n",
    "    ------\n",
    "    `data` has the incorrect number of vertices (59412 or 64984 only\n",
    "        accepted)\n",
    "    \"\"\"\n",
    "    assert data_lh.shape[0] == N_VERTICES_PH[space][density]\n",
    "    assert data_rh.shape[0] == N_VERTICES_PH[space][density]\n",
    "\n",
    "    atlas = fetch_atlas(space, density, data_dir=neuromaps_dir, verbose=0)\n",
    "\n",
    "    medial_lh, medial_rh = atlas[\"medial\"]\n",
    "    wall_lh = nib.load(medial_lh).agg_data()\n",
    "    wall_rh = nib.load(medial_rh).agg_data()\n",
    "\n",
    "    data_lh = data_lh[np.where(wall_lh != 0)]\n",
    "    data_rh = data_rh[np.where(wall_rh != 0)]\n",
    "\n",
    "    if not join:\n",
    "        return data_lh, data_rh\n",
    "\n",
    "    data = np.hstack((data_lh, data_rh))\n",
    "    assert data.shape[0] == N_VERTICES[space][density]\n",
    "    return data\n",
    "\n",
    "\n",
    "def _zero_medial_wall(data_lh, data_rh, space=\"fsLR\", density=\"32k\", neuromaps_dir=None):\n",
    "    \"\"\"Remove medial wall from data in fsLR space.\"\"\"\n",
    "    atlas = fetch_atlas(space, density, data_dir=neuromaps_dir, verbose=0)\n",
    "\n",
    "    medial_lh, medial_rh = atlas[\"medial\"]\n",
    "    medial_arr_lh = nib.load(medial_lh).agg_data()\n",
    "    medial_arr_rh = nib.load(medial_rh).agg_data()\n",
    "\n",
    "    data_arr_lh = data_lh.agg_data()\n",
    "    data_arr_rh = data_rh.agg_data()\n",
    "    data_arr_lh[np.where(medial_arr_lh == 0)] = 0\n",
    "    data_arr_rh[np.where(medial_arr_rh == 0)] = 0\n",
    "\n",
    "    data_lh.remove_gifti_data_array(0)\n",
    "    data_rh.remove_gifti_data_array(0)\n",
    "    data_lh.add_gifti_data_array(GiftiDataArray(data_arr_lh))\n",
    "    data_rh.add_gifti_data_array(GiftiDataArray(data_arr_rh))\n",
    "\n",
    "    return data_lh, data_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vol_to_surf(metamap, space=\"fsLR\", density=\"32k\", return_hemis=False, neuromaps_dir=None):\n",
    "    \"\"\"Transform 4D metamaps from volume to surface space.\"\"\"\n",
    "    if space == \"fsLR\":\n",
    "        metamap_lh, metamap_rh = transforms.mni152_to_fslr(metamap, fslr_density=density)\n",
    "    elif space == \"fsaverage\":\n",
    "        metamap_lh, metamap_rh = transforms.mni152_to_fsaverage(metamap, fsavg_density=density)\n",
    "    elif space == \"civet\":\n",
    "        metamap_lh, metamap_rh = transforms.mni152_to_civet(metamap, civet_density=density)\n",
    "\n",
    "    metamap_lh, metamap_rh = _zero_medial_wall(\n",
    "        metamap_lh,\n",
    "        metamap_rh,\n",
    "        space=space,\n",
    "        density=density,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "    if return_hemis:\n",
    "        return metamap_lh, metamap_rh\n",
    "\n",
    "    metamap_arr_lh = metamap_lh.agg_data()\n",
    "    metamap_arr_rh = metamap_rh.agg_data()\n",
    "\n",
    "    metamap_surf = _rm_medial_wall(\n",
    "        metamap_arr_lh,\n",
    "        metamap_arr_rh,\n",
    "        space=space,\n",
    "        density=density,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    return metamap_surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nifti_to_grayordinate(nifti_fn, axis):\n",
    "    nifti = nib.load(nifti_fn)\n",
    "    nifti_data = nifti.get_fdata(dtype=np.float32)\n",
    "\n",
    "    n_go = axis.name.shape[0]\n",
    "    grayordinate = np.zeros((n_go))\n",
    "\n",
    "    volume_mask = axis.volume_mask\n",
    "    vox_indices = tuple(axis.voxel[volume_mask].T)\n",
    "\n",
    "    grayordinate[volume_mask] = nifti_data[vox_indices]\n",
    "    grayordinate[~volume_mask] = _vol_to_surf(nifti_fn)\n",
    "    \n",
    "    return grayordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(nii_img_thr, threshold, out_file, mask_contours=None, coords=None, vmax=8, alpha=1, cmap=CMAP):\n",
    "    template = datasets.load_mni152_template(resolution=1)\n",
    "\n",
    "    display_modes = [\"x\", \"y\", \"z\"]\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "    for dsp_i, display_mode in enumerate(display_modes):\n",
    "        if display_mode == \"z\":\n",
    "            ax = fig.add_subplot(gs[:, 1], aspect=\"equal\")\n",
    "            colorbar = True\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[dsp_i, 0], aspect=\"equal\")\n",
    "            colorbar = False\n",
    "\n",
    "        if coords is not None:\n",
    "            cut_coords = [coords[dsp_i]]\n",
    "            if np.isnan(cut_coords):\n",
    "                cut_coords = 1\n",
    "        else:\n",
    "            cut_coords = 1\n",
    "\n",
    "        display = plot_stat_map(\n",
    "            nii_img_thr,\n",
    "            bg_img=template,\n",
    "            black_bg=False,\n",
    "            draw_cross=False,\n",
    "            annotate=True,\n",
    "            alpha=alpha,\n",
    "            cmap=cmap,\n",
    "            threshold=threshold,\n",
    "            symmetric_cbar=True,\n",
    "            colorbar=colorbar,\n",
    "            display_mode=display_mode,\n",
    "            cut_coords=cut_coords,\n",
    "            vmax=vmax,\n",
    "            axes=ax,\n",
    "        )\n",
    "        if mask_contours:\n",
    "            display.add_contours(mask_contours, levels=[0.5], colors=\"black\")\n",
    "\n",
    "    fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "\n",
    "def plot_surf(map_lh, map_rh, out_file, mask_contours=None, vmax=8, cmap=CMAP):\n",
    "    surfaces = fetch_fslr(density=\"32k\")\n",
    "    lh, rh = surfaces[\"inflated\"]\n",
    "    sulc_lh, sulc_rh = surfaces[\"sulc\"]\n",
    "\n",
    "    p = Plot(surf_lh=lh, surf_rh=rh, layout=\"grid\")\n",
    "    p.add_layer({\"left\": sulc_lh, \"right\": sulc_rh}, cmap=\"binary_r\", cbar=False)\n",
    "    p.add_layer(\n",
    "        {\"left\": map_lh, \"right\": map_rh}, cmap=cmap, cbar=False, color_range=(-vmax, vmax)\n",
    "    )\n",
    "    if mask_contours:\n",
    "        mask_lh, mask_rh = transforms.mni152_to_fslr(mask_contours, fslr_density=\"32k\")\n",
    "        mask_lh, mask_rh = _zero_medial_wall(\n",
    "            mask_lh,\n",
    "            mask_rh,\n",
    "            space=\"fsLR\",\n",
    "            density=\"32k\",\n",
    "        )\n",
    "        mask_arr_lh = mask_lh.agg_data()\n",
    "        mask_arr_rh = mask_rh.agg_data()\n",
    "        countours_lh = np.zeros_like(mask_arr_lh)\n",
    "        countours_lh[mask_arr_lh != 0] = 1\n",
    "        countours_rh = np.zeros_like(mask_arr_rh)\n",
    "        countours_rh[mask_arr_rh != 0] = 1\n",
    "\n",
    "        colors = [(0, 0, 0, 0)]\n",
    "        contour_cmap = ListedColormap(colors, \"regions\", N=1)\n",
    "        line_cmap = ListedColormap([\"black\"], \"regions\", N=1)\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh},\n",
    "            cmap=line_cmap,\n",
    "            as_outline=True,\n",
    "            cbar=False,\n",
    "        )\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh},\n",
    "            cmap=contour_cmap,\n",
    "            cbar=False,\n",
    "        )\n",
    "    fig = p.build()\n",
    "    fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPI = 300\n",
    "VMAX = 12\n",
    "C_EXTENT = 90\n",
    "P_THRESH = 0.001\n",
    "Z_THRESH = p_to_z(P_THRESH, tail=\"two\")\n",
    "\n",
    "CMAP = nilearn_cmaps[\"cold_hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_dir = \"/Users/julioaperaza/Downloads/HCP_S1200_GroupAvg_v1\"\n",
    "hcp_task_dir = \"/Users/julioaperaza/Documents/GitHub/large-scale-ibma/temp/hcp_tasks\"\n",
    "hcp_fn = op.join(hcp_dir, \"HCP_S1200_997_tfMRI_ALLTASKS_level2_cohensd_hp200_s2_MSMAll.dscalar.nii\")\n",
    "hcp_maps = nib.load(hcp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_data = hcp_maps.get_fdata(dtype=np.float32)\n",
    "cifti_hdr = hcp_maps.header\n",
    "hcp_axis = cifti_hdr.get_axis(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_max_val(map_thr):\n",
    "    data = map_thr.get_fdata()\n",
    "    mask = ~np.isnan(data) & (data != 0)\n",
    "    data = data[mask]\n",
    "    max_val = 3 if len(data) == 0 else np.max(np.abs(data))\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "    \"Stouffers\\nIndependent Contrasts\",\n",
    "    \"Weighted Stouffers\\nIndependent Contrasts\",\n",
    "    \"Stouffers\\nNon-independent Contrasts\",\n",
    "    \"Weighted Stouffers\\nNon-independent Contrasts\",\n",
    "    \"Weighted Stouffers\\nDownweighted by Study Size\\nNon-independent Contrasts\",\n",
    "    \"Fixed Effects\\nHedges' g\",\n",
    "    \"HCP\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 7\n",
    "w = 1.5 * n_cols\n",
    "h = 1.2 * n_rows\n",
    "\n",
    "result_fns = [\n",
    "    \"no-hcp_stouffers_result.pkl.gz\",\n",
    "    \"no-hcp_stouffers-weighted_result.pkl.gz\",\n",
    "    \"no-hcp_stouffers-ncontrast_result.pkl.gz\",\n",
    "    \"no-hcp_stouffers-ncontrast-weighted_result.pkl.gz\",\n",
    "    \"no-hcp_stouffers-ncontrast-weighted-downweighted_result.pkl.gz\",\n",
    "    \"no-hcp_fe-hedges_result.pkl.gz\",\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    # \"emotion_processing_fmri_task_paradigm\",\n",
    "    # \"language_processing_fmri_task_paradigm\",\n",
    "    # \"motor_fmri_task_paradigm\",\n",
    "    # \"social_cognition_(theory_of_mind)_fmri_task_paradigm\",\n",
    "    \"working_memory_fmri_task_paradigm\",\n",
    "]\n",
    "mode = \"manual\"\n",
    "\n",
    "results_dir = '../results'\n",
    "outputs_dir = './stouffers_variations'\n",
    "outputs_dir = op.join(outputs_dir, mode)\n",
    "os.makedirs(outputs_dir, exist_ok=True)\n",
    "for task in tasks:\n",
    "    out_file = op.join(outputs_dir, f\"{task}.png\")\n",
    "\n",
    "    fig = plt.figure(figsize=(w, h))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "    gs = GridSpec(n_rows, n_cols, figure=fig)\n",
    "\n",
    "    coords = None\n",
    "    data_lst = []\n",
    "    for col, result_fn in enumerate(result_fns):\n",
    "        file_name = op.join(results_dir, \"ibma\", task, mode, result_fn)\n",
    "        result = MetaResult.load(file_name)\n",
    "        \n",
    "        z_map = result.maps[\"z\"]\n",
    "        z_map = np.nan_to_num(z_map, nan=0.0)\n",
    "        dof_map = result.maps[\"dof\"]\n",
    "        t_map = np.array([z_to_t(z_val, dof) for z_val, dof in zip(z_map, dof_map)])\n",
    "        cohens_maps = t_to_d(t_map, dof_map + 1)\n",
    "        hedges_maps = d_to_g(cohens_maps, dof_map + 1)\n",
    "\n",
    "        # ibma_data = np.nan_to_num(ibma_data, nan=0.0)\n",
    "        # ibma_img = nib.Nifti1Image(ibma_data, ibma_img.affine, ibma_img.header)\n",
    "        ibma_img = result.masker.inverse_transform(hedges_maps)\n",
    "        \n",
    "        # Define temp out files\n",
    "        ibma_img_fn = op.join(outputs_dir, f\"{task}_map-{col}.nii.gz\")\n",
    "        ibma_img_thr_fn = op.join(outputs_dir, f\"{task}_map-{col}_thr.nii.gz\")\n",
    "        nib.save(ibma_img, ibma_img_fn)\n",
    "\n",
    "        # GEt image grayordinate for correlation matrix\n",
    "        ibma_img_grayordinate = nifti_to_grayordinate(ibma_img_fn, hcp_axis)\n",
    "        data_lst.append(ibma_img_grayordinate)\n",
    "\n",
    "        # Plotting ===============================================================\n",
    "        # Threshold image\n",
    "        # img_thr = threshold_img(ibma_img, Z_THRESH, two_sided=True, cluster_threshold=C_EXTENT)\n",
    "        if coords is None:\n",
    "            # coords = find_xyz_cut_coords(img_thr)\n",
    "            coords = find_xyz_cut_coords(ibma_img)\n",
    "\n",
    "        \n",
    "        # Get gifti for surface plotting\n",
    "        # nib.save(img_thr, ibma_img_thr_fn)\n",
    "        # img_thr_lh, img_thr_rh = _vol_to_surf(ibma_img_thr_fn, return_hemis=True)\n",
    "        img_lh, img_rh = _vol_to_surf(ibma_img_fn, return_hemis=True)\n",
    "\n",
    "        # Plotting\n",
    "        vol_fn = op.join(outputs_dir, f\"{task}_map-{col}_vol.png\")\n",
    "        surf_fn = op.join(outputs_dir, f\"{task}_map-{col}_surf.png\")\n",
    "        # plot_vol(img_thr, Z_THRESH, vol_fn, coords=coords, vmax=VMAX)\n",
    "        plot_vol(ibma_img, 0, vol_fn, coords=coords, vmax=1, cmap=\"coolwarm\")\n",
    "        plot_surf(img_lh, img_rh, surf_fn, vmax=1, cmap=\"coolwarm\")\n",
    "\n",
    "        # Add images to figure\n",
    "        for row, img_file in enumerate([vol_fn, surf_fn]):\n",
    "            img = mpimg.imread(img_file)\n",
    "            ax = fig.add_subplot(gs[row, col], aspect=\"equal\")\n",
    "            ax.imshow(img)\n",
    "            ax.set_axis_off()\n",
    "        \n",
    "            if row == 0:\n",
    "                ax.set_title(titles[col], fontsize=5)\n",
    "\n",
    "    # Plot HCP data\n",
    "    hcp_img_lh = nib.load(op.join(hcp_task_dir, f\"{TASK_TO_HCP[task]}_lh.gii\"))\n",
    "    hcp_img_rh = nib.load(op.join(hcp_task_dir, f\"{TASK_TO_HCP[task]}_rh.gii\")) \n",
    "    hcp_img = nib.load(op.join(hcp_task_dir, f\"{TASK_TO_HCP[task]}_subcort.nii.gz\"))\n",
    "    hcp_img_grayordinate = np.load(op.join(hcp_task_dir, f\"{TASK_TO_HCP[task]}.npy\"))\n",
    "    \n",
    "    data_lst.append(hcp_img_grayordinate)\n",
    "    vol_fn = op.join(outputs_dir, f\"{task}_map-hcp_vol.png\")\n",
    "    surf_fn = op.join(outputs_dir, f\"{task}_map-hcp_surf.png\")\n",
    "    plot_vol(hcp_img, 0, vol_fn, coords=coords, vmax=1, cmap=\"coolwarm\")\n",
    "    plot_surf(hcp_img_lh, hcp_img_rh, surf_fn, vmax=1, cmap=\"coolwarm\")\n",
    "    for row, img_file in enumerate([vol_fn, surf_fn]):\n",
    "        img = mpimg.imread(img_file)\n",
    "        ax = fig.add_subplot(gs[row, -1], aspect=\"equal\")\n",
    "        ax.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title(titles[-1], fontsize=5)\n",
    "    \n",
    "    # Add title\n",
    "    fig.suptitle(task.replace(\"_\", \" \"), fontsize=7)\n",
    "\n",
    "    # Make sure the axis size if the same for different labels sizes\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    fig.savefig(out_file, bbox_inches=\"tight\", dpi=DPI)\n",
    "    fig.show()\n",
    "\n",
    "    data_arr = np.array(data_lst)\n",
    "    corr_mat = np.corrcoef(data_arr)\n",
    "\n",
    "    fig_hm, ax_hm = plt.subplots(figsize=(10, 7))\n",
    "    sns.heatmap(\n",
    "        corr_mat, \n",
    "        annot=True, \n",
    "        fmt=\".2f\", \n",
    "        cmap=\"Reds\",\n",
    "        square=True,\n",
    "        xticklabels=titles, \n",
    "        yticklabels=titles,\n",
    "        ax=ax_hm,\n",
    "    )\n",
    "    fig_hm.savefig(op.join(outputs_dir, f\"{task}_corr-mat.png\"), bbox_inches=\"tight\", dpi=DPI)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fn = op.join(results_dir, \"hedges\", \"neurovault_result.pkl.gz\")\n",
    "result = MetaResult.load(result_fn)\n",
    "img = result.get_map(\"z_corr-FDR_method-indep\")\n",
    "\n",
    "img_thr = threshold_img(img, Z_THRESH, two_sided=False, cluster_threshold=C_EXTENT)\n",
    "nib.save(img_thr, op.join(outputs_dir, \"hedges_thr.nii.gz\"))\n",
    "\n",
    "vol_fn = op.join(outputs_dir, \"hedges_vol.png\")\n",
    "surf_fn = op.join(outputs_dir, \"hedges_surf.png\")\n",
    "\n",
    "plot_vol(img_thr, Z_THRESH, vol_fn, vmax=VMAX)\n",
    "plot_surf(op.join(outputs_dir, \"hedges_thr.nii.gz\"), surf_fn, vmax=VMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
